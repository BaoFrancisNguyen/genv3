"""
Service de G√©n√©ration - Couche m√©tier pour la g√©n√©ration de donn√©es √©lectriques
==============================================================================

Ce service orchestre la g√©n√©ration compl√®te des donn√©es √©lectriques.
"""

import logging
import pandas as pd
from datetime import datetime
from typing import Dict, List, Optional

from src.core.generator import ElectricityDataGenerator
from src.models.building import Building


# Configuration du logger
logger = logging.getLogger(__name__)


class GenerationService:
    """
    Service m√©tier pour la g√©n√©ration de donn√©es √©lectriques
    
    Coordonne la g√©n√©ration compl√®te en g√©rant la validation,
    l'optimisation et la qualit√© des donn√©es produites.
    """
    
    def __init__(self, generator: ElectricityDataGenerator):
        """
        Initialise le service de g√©n√©ration
        
        Args:
            generator: Instance du g√©n√©rateur de donn√©es √©lectriques
        """
        self.generator = generator
        self.service_statistics = {
            'total_generations': 0,
            'successful_generations': 0,
            'total_buildings_processed': 0,
            'total_observations_created': 0,
            'service_start_time': datetime.now()
        }
        
        logger.info("‚úÖ Service de g√©n√©ration initialis√©")
    
    def generate_complete_dataset(
        self,
        zone_name: str,
        buildings_osm: List[Dict],
        start_date: str,
        end_date: str,
        frequency: str = '30T'
    ) -> Dict:
        """
        G√©n√®re un dataset complet avec b√¢timents et s√©ries temporelles
        
        Args:
            zone_name: Nom de la zone
            buildings_osm: Donn√©es des b√¢timents OSM
            start_date: Date de d√©but (YYYY-MM-DD)
            end_date: Date de fin (YYYY-MM-DD)
            frequency: Fr√©quence d'√©chantillonnage
            
        Returns:
            Dict: Dataset complet avec m√©tadonn√©es
        """
        try:
            logger.info(f"üîÑ G√©n√©ration dataset complet - Zone: {zone_name}")
            logger.info(f"üìä {len(buildings_osm)} b√¢timents, p√©riode: {start_date} ‚Üí {end_date}")
            
            # Mise √† jour des statistiques
            self.service_statistics['total_generations'] += 1
            
            # Phase 1: Validation des param√®tres
            validation_result = self._validate_generation_request(
                buildings_osm, start_date, end_date, frequency
            )
            
            if not validation_result['valid']:
                logger.error(f"‚ùå Validation √©chou√©e: {validation_result['errors']}")
                return {
                    'success': False,
                    'error': 'Param√®tres invalides',
                    'validation_errors': validation_result['errors']
                }
            
            # Phase 2: Conversion des b√¢timents OSM en objets Building
            logger.info("üèóÔ∏è Conversion des b√¢timents OSM...")
            buildings_conversion = self._convert_osm_to_buildings(buildings_osm, zone_name)
            
            if not buildings_conversion['success']:
                logger.error(f"‚ùå Conversion OSM √©chou√©e: {buildings_conversion.get('error')}")
                return buildings_conversion
            
            buildings = buildings_conversion['buildings']
            self.service_statistics['total_buildings_processed'] += len(buildings)
            
            # Phase 3: G√©n√©ration des m√©tadonn√©es de b√¢timents
            logger.info("üìã G√©n√©ration des m√©tadonn√©es...")
            buildings_df = self.generator.generate_building_metadata(buildings)
            
            # Phase 4: G√©n√©ration des s√©ries temporelles
            logger.info("‚è∞ G√©n√©ration des s√©ries temporelles...")
            timeseries_df = self.generator.generate_timeseries_for_buildings(
                buildings, start_date, end_date, frequency
            )
            
            self.service_statistics['total_observations_created'] += len(timeseries_df)
            
            # Phase 5: Validation et nettoyage des donn√©es g√©n√©r√©es
            logger.info("üßπ Contr√¥le qualit√©...")
            quality_check = self._perform_quality_check(buildings_df, timeseries_df)
            
            # Phase 6: G√©n√©ration du r√©sum√© statistique
            summary = self.generator.get_generation_summary(buildings, timeseries_df)
            
            # Mise √† jour des statistiques de succ√®s
            self.service_statistics['successful_generations'] += 1
            
            # Construction de la r√©ponse compl√®te
            response = {
                'success': True,
                'zone_name': zone_name,
                'generation_timestamp': datetime.now().isoformat(),
                'buildings_data': buildings_df.to_dict('records'),
                'timeseries_data': timeseries_df.to_dict('records'),
                'statistics': {
                    'total_buildings': len(buildings),
                    'total_observations': len(timeseries_df),
                    'date_range': {
                        'start': start_date,
                        'end': end_date,
                        'frequency': frequency
                    },
                    'generation_summary': summary,
                    'quality_metrics': quality_check
                },
                'conversion_info': buildings_conversion['conversion_info'],
                'validation_warnings': validation_result.get('warnings', [])
            }
            
            logger.info(f"‚úÖ G√©n√©ration termin√©e: {len(timeseries_df)} observations cr√©√©es")
            return response
            
        except Exception as e:
            self.service_statistics['total_generations'] += 1  # Compter les √©checs aussi
            logger.error(f"‚ùå Erreur g√©n√©ration dataset: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())
            return {
                'success': False,
                'error': f"Erreur de g√©n√©ration: {str(e)}",
                'zone_name': zone_name
            }
    
    def _validate_generation_request(
        self,
        buildings_osm: List[Dict],
        start_date: str,
        end_date: str,
        frequency: str
    ) -> Dict:
        """
        Valide une requ√™te de g√©n√©ration compl√®te
        
        Args:
            buildings_osm: Donn√©es des b√¢timents OSM
            start_date: Date de d√©but
            end_date: Date de fin
            frequency: Fr√©quence
            
        Returns:
            Dict: R√©sultats de validation
        """
        errors = []
        warnings = []
        
        # Validation des b√¢timents OSM
        if not buildings_osm:
            errors.append("Aucun b√¢timent OSM fourni")
        elif len(buildings_osm) > 50000:
            errors.append("Trop de b√¢timents (max 50000)")
        elif len(buildings_osm) > 10000:
            warnings.append("Grand nombre de b√¢timents - g√©n√©ration longue")
        
        # Validation des param√®tres temporels
        try:
            start = pd.to_datetime(start_date)
            end = pd.to_datetime(end_date)
            
            if start >= end:
                errors.append("Date de fin doit √™tre apr√®s date de d√©but")
            
            if (end - start).days > 365:
                errors.append("P√©riode maximale: 365 jours")
                
        except Exception as e:
            errors.append(f"Format de dates invalide: {str(e)}")
        
        # Validation fr√©quence
        valid_frequencies = ['15T', '30T', '1H', '3H', 'D']
        if frequency not in valid_frequencies:
            errors.append(f"Fr√©quence invalide. Support√©es: {valid_frequencies}")
        
        # Validation de la coh√©rence des donn√©es OSM
        osm_validation = self._validate_osm_data_quality(buildings_osm)
        if osm_validation['warnings']:
            warnings.extend(osm_validation['warnings'])
        if osm_validation['critical_errors']:
            errors.extend(osm_validation['critical_errors'])
        
        return {
            'valid': len(errors) == 0,
            'errors': errors,
            'warnings': warnings,
            'osm_quality_score': osm_validation['quality_score']
        }
    
    def _validate_osm_data_quality(self, buildings_osm: List[Dict]) -> Dict:
        """
        Valide la qualit√© des donn√©es OSM
        
        Args:
            buildings_osm: Donn√©es des b√¢timents OSM
            
        Returns:
            Dict: √âvaluation de qualit√©
        """
        if not buildings_osm:
            return {
                'quality_score': 0,
                'warnings': [],
                'critical_errors': ['Aucune donn√©e OSM']
            }
        
        warnings = []
        critical_errors = []
        quality_metrics = {
            'has_coordinates': 0,
            'has_building_type': 0,
            'has_valid_coordinates': 0,
            'has_osm_id': 0
        }
        
        for i, building_data in enumerate(buildings_osm):
            # V√©rification coordonn√©es
            lat = building_data.get('latitude') or building_data.get('lat')
            lon = building_data.get('longitude') or building_data.get('lon')
            
            if lat is not None and lon is not None:
                quality_metrics['has_coordinates'] += 1
                
                # Validation coordonn√©es Malaysia
                try:
                    lat_f, lon_f = float(lat), float(lon)
                    if 0.5 <= lat_f <= 7.5 and 99.0 <= lon_f <= 120.0:
                        quality_metrics['has_valid_coordinates'] += 1
                    else:
                        warnings.append(f"B√¢timent {i}: coordonn√©es hors Malaysia")
                except:
                    warnings.append(f"B√¢timent {i}: coordonn√©es non num√©riques")
            
            # V√©rification type de b√¢timent
            building_type = building_data.get('building_type')
            if building_type:
                quality_metrics['has_building_type'] += 1
            
            # V√©rification ID OSM
            osm_id = building_data.get('osm_id') or building_data.get('id')
            if osm_id:
                quality_metrics['has_osm_id'] += 1
        
        # Calcul du score de qualit√©
        total_buildings = len(buildings_osm)
        coord_score = (quality_metrics['has_valid_coordinates'] / total_buildings) * 40
        type_score = (quality_metrics['has_building_type'] / total_buildings) * 30
        id_score = (quality_metrics['has_osm_id'] / total_buildings) * 30
        
        quality_score = coord_score + type_score + id_score
        
        return {
            'quality_score': round(quality_score, 1),
            'warnings': warnings,
            'critical_errors': critical_errors,
            'metrics': quality_metrics
        }
    
    def _convert_osm_to_buildings(self, buildings_osm: List[Dict], zone_name: str) -> Dict:
        """
        Convertit les donn√©es OSM en objets Building
        
        Args:
            buildings_osm: Donn√©es OSM des b√¢timents
            zone_name: Nom de la zone
            
        Returns:
            Dict: R√©sultat de conversion
        """
        try:
            buildings = []
            conversion_stats = {
                'processed': 0,
                'converted': 0,
                'skipped': 0,
                'errors': []
            }
            
            for i, osm_data in enumerate(buildings_osm):
                conversion_stats['processed'] += 1
                
                try:
                    # Extraction des coordonn√©es
                    lat = osm_data.get('latitude') or osm_data.get('lat')
                    lon = osm_data.get('longitude') or osm_data.get('lon')
                    
                    if lat is None or lon is None:
                        conversion_stats['skipped'] += 1
                        continue
                    
                    # Cr√©ation de l'objet Building
                    building = Building(
                        osm_id=str(osm_data.get('osm_id', osm_data.get('id', f'gen_{i}'))),
                        latitude=float(lat),
                        longitude=float(lon),
                        building_type=osm_data.get('building_type', 'residential'),
                        surface_area_m2=osm_data.get('surface_area_m2', 100.0),
                        base_consumption_kwh=osm_data.get('base_consumption_kwh', 15.0),
                        zone_name=zone_name,
                        osm_tags=osm_data.get('osm_tags', {})
                    )
                    
                    buildings.append(building)
                    conversion_stats['converted'] += 1
                    
                except Exception as e:
                    conversion_stats['skipped'] += 1
                    conversion_stats['errors'].append(f"B√¢timent {i}: {str(e)}")
            
            success_rate = (conversion_stats['converted'] / conversion_stats['processed']) * 100
            
            return {
                'success': conversion_stats['converted'] > 0,
                'buildings': buildings,
                'conversion_info': {
                    'success_rate_percent': round(success_rate, 1),
                    'statistics': conversion_stats
                }
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f"Erreur conversion OSM: {str(e)}",
                'buildings': []
            }
    
    def _perform_quality_check(self, buildings_df: pd.DataFrame, timeseries_df: pd.DataFrame) -> Dict:
        """
        Effectue un contr√¥le qualit√© sur les donn√©es g√©n√©r√©es
        
        Args:
            buildings_df: DataFrame des b√¢timents
            timeseries_df: DataFrame des s√©ries temporelles
            
        Returns:
            Dict: M√©triques de qualit√©
        """
        quality_metrics = {
            'overall_score': 100.0,
            'buildings_quality': {},
            'timeseries_quality': {},
            'issues': []
        }
        
        # Contr√¥le qualit√© des b√¢timents
        if not buildings_df.empty:
            # V√©rification des doublons
            duplicates = buildings_df.duplicated(subset=['latitude', 'longitude']).sum()
            if duplicates > 0:
                quality_metrics['overall_score'] -= 5
                quality_metrics['issues'].append(f"{duplicates} b√¢timents doublons")
            
            # V√©rification des coordonn√©es
            invalid_coords = ((buildings_df['latitude'] < 0.5) | 
                            (buildings_df['latitude'] > 7.5) |
                            (buildings_df['longitude'] < 99.0) | 
                            (buildings_df['longitude'] > 120.0)).sum()
            
            if invalid_coords > 0:
                quality_metrics['overall_score'] -= 10
                quality_metrics['issues'].append(f"{invalid_coords} coordonn√©es invalides")
            
            quality_metrics['buildings_quality'] = {
                'total_buildings': len(buildings_df),
                'duplicates': duplicates,
                'invalid_coordinates': invalid_coords
            }
        
        # Contr√¥le qualit√© des s√©ries temporelles
        if not timeseries_df.empty:
            # V√©rification des valeurs n√©gatives
            negative_values = (timeseries_df['consumption_kwh'] < 0).sum()
            if negative_values > 0:
                quality_metrics['overall_score'] -= 15
                quality_metrics['issues'].append(f"{negative_values} valeurs n√©gatives")
            
            # V√©rification des valeurs nulles
            null_values = timeseries_df['consumption_kwh'].isnull().sum()
            if null_values > 0:
                quality_metrics['overall_score'] -= 20
                quality_metrics['issues'].append(f"{null_values} valeurs nulles")
            
            # V√©rification de la coh√©rence temporelle
            if 'timestamp' in timeseries_df.columns:
                time_gaps = timeseries_df['timestamp'].duplicated().sum()
                if time_gaps > 0:
                    quality_metrics['overall_score'] -= 5
                    quality_metrics['issues'].append(f"{time_gaps} doublons temporels")
            
            quality_metrics['timeseries_quality'] = {
                'total_observations': len(timeseries_df),
                'negative_values': negative_values,
                'null_values': null_values,
                'mean_consumption': timeseries_df['consumption_kwh'].mean(),
                'std_consumption': timeseries_df['consumption_kwh'].std()
            }
        
        quality_metrics['overall_score'] = max(0.0, quality_metrics['overall_score'])
        return quality_metrics
    
    def estimate_generation_resources(
        self,
        num_buildings: int,
        start_date: str,
        end_date: str,
        frequency: str
    ) -> Dict:
        """
        Estime les ressources n√©cessaires pour la g√©n√©ration
        
        Args:
            num_buildings: Nombre de b√¢timents
            start_date: Date de d√©but
            end_date: Date de fin
            frequency: Fr√©quence
            
        Returns:
            Dict: Estimation des ressources
        """
        try:
            # Calcul du nombre d'observations
            start = pd.to_datetime(start_date)
            end = pd.to_datetime(end_date)
            date_range = pd.date_range(start=start, end=end, freq=frequency)
            
            total_observations = num_buildings * len(date_range)
            
            # Estimation du temps (approximatif)
            observations_per_second = 10000  # Calibr√© selon les performances
            estimated_time_seconds = total_observations / observations_per_second
            
            # Estimation de la taille m√©moire (approximatif)
            bytes_per_observation = 100  # Estimation
            estimated_memory_mb = (total_observations * bytes_per_observation) / (1024 * 1024)
            
            # Niveau de complexit√©
            if total_observations < 50000:
                complexity = 'simple'
                recommendation = 'G√©n√©ration rapide'
            elif total_observations < 500000:
                complexity = 'mod√©r√©'
                recommendation = 'G√©n√©ration standard'
            elif total_observations < 2000000:
                complexity = 'complexe'
                recommendation = 'G√©n√©ration longue - soyez patient'
            else:
                complexity = 'tr√®s_complexe'
                recommendation = 'G√©n√©ration tr√®s longue - consid√©rer la r√©duction'
            
            return {
                'num_buildings': num_buildings,
                'date_range_days': (end - start).days,
                'frequency': frequency,
                'total_observations': total_observations,
                'estimated_time_seconds': round(estimated_time_seconds, 1),
                'estimated_time_minutes': round(estimated_time_seconds / 60, 1),
                'estimated_memory_mb': round(estimated_memory_mb, 1),
                'complexity_level': complexity,
                'recommendation': recommendation
            }
            
        except Exception as e:
            return {
                'error': f"Erreur estimation: {str(e)}",
                'num_buildings': num_buildings,
                'complexity_level': 'unknown'
            }
    
    def get_service_status(self) -> Dict:
        """
        Retourne le statut du service de g√©n√©ration
        
        Returns:
            Dict: Statut et statistiques du service
        """
        uptime = datetime.now() - self.service_statistics['service_start_time']
        
        success_rate = 0
        if self.service_statistics['total_generations'] > 0:
            success_rate = (
                self.service_statistics['successful_generations'] / 
                self.service_statistics['total_generations']
            ) * 100
        
        return {
            'service_name': 'Generation Service',
            'status': 'active',
            'uptime_seconds': int(uptime.total_seconds()),
            'statistics': {
                'total_generations': self.service_statistics['total_generations'],
                'successful_generations': self.service_statistics['successful_generations'],
                'success_rate_percent': round(success_rate, 1),
                'total_buildings_processed': self.service_statistics['total_buildings_processed'],
                'total_observations_created': self.service_statistics['total_observations_created']
            }
        }
    
    def get_statistics(self) -> Dict:
        """
        Retourne les statistiques d√©taill√©es du service
        
        Returns:
            Dict: Statistiques compl√®tes
        """
        return self.service_statistics.copy()


# ==============================================================================
# FONCTIONS UTILITAIRES DU SERVICE
# ==============================================================================

def calculate_generation_complexity(
    num_buildings: int,
    date_range_days: int,
    frequency_minutes: int
) -> str:
    """
    Calcule le niveau de complexit√© d'une g√©n√©ration
    
    Args:
        num_buildings: Nombre de b√¢timents
        date_range_days: Nombre de jours
        frequency_minutes: Fr√©quence en minutes
        
    Returns:
        str: Niveau de complexit√©
    """
    points_per_day = (24 * 60) / frequency_minutes
    total_points = num_buildings * date_range_days * points_per_day
    
    if total_points < 10000:
        return 'simple'
    elif total_points < 100000:
        return 'mod√©r√©'
    elif total_points < 1000000:
        return 'complexe'
    else:
        return 'tr√®s_complexe'


# ==============================================================================
# EXEMPLE D'UTILISATION
# ==============================================================================

if __name__ == '__main__':
    # Test du service de g√©n√©ration
    from src.core.generator import ElectricityDataGenerator
    
    # Initialisation
    generator = ElectricityDataGenerator()
    generation_service = GenerationService(generator)
    
    # Donn√©es OSM de test
    test_osm_buildings = [
        {
            'osm_id': '12345',
            'latitude': 3.15,
            'longitude': 101.7,
            'building_type': 'residential',
            'tags': {'building': 'residential'}
        },
        {
            'osm_id': '12346',
            'latitude': 3.16,
            'longitude': 101.71,
            'building_type': 'commercial',
            'tags': {'building': 'commercial'}
        }
    ]
    
    # Test de g√©n√©ration
    result = generation_service.generate_complete_dataset(
        zone_name='test_zone',
        buildings_osm=test_osm_buildings,
        start_date='2024-01-01',
        end_date='2024-01-02',
        frequency='1H'
    )
    
    if result['success']:
        print(f"‚úÖ G√©n√©ration test r√©ussie:")
        print(f"üìä {result['statistics']['total_buildings']} b√¢timents")
        print(f"‚è∞ {result['statistics']['total_observations']} observations")
        print(f"üéØ Score qualit√©: {result['statistics']['quality_metrics']['overall_score']}")
    else:
        print(f"‚ùå G√©n√©ration √©chou√©e: {result['error']}")
    
    # Statut du service
    status = generation_service.get_service_status()
    print(f"üìà Service: {status['statistics']['success_rate_percent']}% succ√®s")